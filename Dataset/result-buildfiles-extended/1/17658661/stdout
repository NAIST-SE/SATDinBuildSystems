{
  "Repository" : "17658661",
  "Revision" : "HEAD",
  "ObjectId" : "793e0fb04f3bddc16cacc237b177d8d9793b2e3e",
  "CommitTime" : "2018-11-23T18:02:36Z",
  "Files" : {
    "Makefile.am" : {
      "ObjectId" : "65e44b2e5e21b739396fbc1abffe7efa702d7a1c",
      "LastModified" : "2017-10-13T13:29:10Z",
      "FileType" : "AUTOMAKE",
      "0" : {
        "Text" : "## Process this file with automake to produce Makefile.in\n\n## Author: Tommi A Pirinen <flammie@iki.fi>\n\n## Licence: GPL v3 (not newer)\n",
        "Line" : 1,
        "CharPositionInLine" : 0
      },
      "1" : {
        "Text" : "## N.B. GNU standards COPYING AUTHORS INSTALL README NEWS need not be declared\n",
        "Line" : 5,
        "CharPositionInLine" : 0
      },
      "CommentCount" : 2
    },
    "doc/Makefile.am" : {
      "ObjectId" : "192887472225fe5cb557aea61bcba7d9da18630c",
      "LastModified" : "2015-01-10T16:18:48Z",
      "FileType" : "AUTOMAKE",
      "0" : {
        "Text" : "## Process this file with automake to produce Makefile.in\n",
        "Line" : 1,
        "CharPositionInLine" : 0
      },
      "CommentCount" : 1
    },
    "man/Makefile.am" : {
      "ObjectId" : "cb635f23e8d217935ac372a67e2a0e9ec8c649b5",
      "LastModified" : "2018-06-26T15:11:22Z",
      "FileType" : "AUTOMAKE",
      "0" : {
        "Text" : "## Process this file with automake to produce Makefile.in\n",
        "Line" : 1,
        "CharPositionInLine" : 0
      },
      "CommentCount" : 1
    },
    "src/Makefile.am" : {
      "ObjectId" : "e317f2a661d25986052f44384886e75e8f88f77d",
      "LastModified" : "2018-11-16T18:02:06Z",
      "FileType" : "AUTOMAKE",
      "0" : {
        "Text" : "## Process this file with automake to produce Makefile.in\n",
        "Line" : 1,
        "CharPositionInLine" : 0
      },
      "1" : {
        "Text" : "# Settings\n",
        "Line" : 3,
        "CharPositionInLine" : 0
      },
      "2" : {
        "Text" : "# {{{ Files\n\n# Origins\n",
        "Line" : 11,
        "CharPositionInLine" : 0
      },
      "3" : {
        "Text" : "# Lexicography\n\n#\n",
        "Line" : 14,
        "CharPositionInLine" : 0
      },
      "4" : {
        "Text" : "# lexical features\n",
        "Line" : 17,
        "CharPositionInLine" : 0
      },
      "5" : {
        "Text" : "# paradigm features\n",
        "Line" : 35,
        "CharPositionInLine" : 0
      },
      "6" : {
        "Text" : "# Tokenisation\n",
        "Line" : 39,
        "CharPositionInLine" : 0
      },
      "7" : {
        "Text" : "# }}}\n\n#\n\n# {{{Scripts\n\n# NB: (variable name = SCIRPTS cause automagic _SCRIPTS)\n\n# tag formats\n",
        "Line" : 41,
        "CharPositionInLine" : 0
      },
      "8" : {
        "Text" : "# file formats\n",
        "Line" : 60,
        "CharPositionInLine" : 0
      },
      "9" : {
        "Text" : "# Raw-ish database handling\n",
        "Line" : 69,
        "CharPositionInLine" : 0
      },
      "10" : {
        "Text" : "# Finnish specific lot\n",
        "Line" : 72,
        "CharPositionInLine" : 0
      },
      "11" : {
        "Text" : "# }}}\n\n#\n\n# {{{Generated files\n",
        "Line" : 85,
        "CharPositionInLine" : 0
      },
      "12" : {
        "Text" : "# hyphenate-dict is unusable atm\n",
        "Line" : 99,
        "CharPositionInLine" : 0
      },
      "13" : {
        "Text" : "# }}}\n\n# {{{Autotools install\n\n# destnations directories for this stuff at the top of the file\n",
        "Line" : 165,
        "CharPositionInLine" : 0
      },
      "14" : {
        "Text" : "# Actual python API omorfi.* (no need to add unused internal stuff)\n",
        "Line" : 199,
        "CharPositionInLine" : 0
      },
      "15" : {
        "Text" : "# These go into dist tarballs... which we no longer make\n\n# N.B. for distcheck anyways\n",
        "Line" : 222,
        "CharPositionInLine" : 0
      },
      "16" : {
        "Text" : "# These are ran with make check. All modules should have stuff\n",
        "Line" : 261,
        "CharPositionInLine" : 0
      },
      "17" : {
        "Text" : "# python is anti-unit tests\n\n# https://stackoverflow.com/questions/16981921/relative-imports-in-python-3\n",
        "Line" : 272,
        "CharPositionInLine" : 0
      },
      "18" : {
        "Text" : "# These aren't installed but generated\n",
        "Line" : 277,
        "CharPositionInLine" : 0
      },
      "19" : {
        "Text" : "# Things that make clean isn't smart enought to wipe\n",
        "Line" : 280,
        "CharPositionInLine" : 0
      },
      "20" : {
        "Text" : "# }}}\n\n#\n\n# {{{GENERATING \n",
        "Line" : 283,
        "CharPositionInLine" : 0
      },
      "21" : {
        "Text" : "# database to database\n",
        "Line" : 291,
        "CharPositionInLine" : 0
      },
      "22" : {
        "Text" : "#\n",
        "Line" : 309,
        "CharPositionInLine" : 0
      },
      "23" : {
        "Text" : "# database to omorfi native lexcies:\n\n# segmenter\n",
        "Line" : 320,
        "CharPositionInLine" : 0
      },
      "24" : {
        "Text" : "# lemmatiser\n",
        "Line" : 327,
        "CharPositionInLine" : 0
      },
      "25" : {
        "Text" : "# acceptor\n",
        "Line" : 334,
        "CharPositionInLine" : 0
      },
      "26" : {
        "Text" : "# segmented analysis experiment\n",
        "Line" : 341,
        "CharPositionInLine" : 0
      },
      "27" : {
        "Text" : "# YAML tests\n",
        "Line" : 347,
        "CharPositionInLine" : 0
      },
      "28" : {
        "Text" : "# baseline reweighter\n",
        "Line" : 351,
        "CharPositionInLine" : 0
      },
      "29" : {
        "Text" : "# Gold dictionary lexc: kotus + omorfi++ - FGK - PROPN blockers\n",
        "Line" : 355,
        "CharPositionInLine" : 0
      },
      "30" : {
        "Text" : "# Real omorfi dictionary\n",
        "Line" : 363,
        "CharPositionInLine" : 0
      },
      "31" : {
        "Text" : "# Xerox style guesser\n",
        "Line" : 370,
        "CharPositionInLine" : 0
      },
      "32" : {
        "Text" : "# hacks\n",
        "Line" : 376,
        "CharPositionInLine" : 0
      },
      "33" : {
        "Text" : "# misc twol rules\n",
        "Line" : 381,
        "CharPositionInLine" : 0
      },
      "34" : {
        "Text" : "# recasing optional rules\n",
        "Line" : 385,
        "CharPositionInLine" : 0
      },
      "35" : {
        "Text" : "# uppercasing optional rules\n",
        "Line" : 389,
        "CharPositionInLine" : 0
      },
      "36" : {
        "Text" : "# titlecasing optional rules\n",
        "Line" : 393,
        "CharPositionInLine" : 0
      },
      "37" : {
        "Text" : "# hyphenation rules\n",
        "Line" : 397,
        "CharPositionInLine" : 0
      },
      "38" : {
        "Text" : "# orthography rules\n",
        "Line" : 401,
        "CharPositionInLine" : 0
      },
      "39" : {
        "Text" : "# ž rules\n",
        "Line" : 406,
        "CharPositionInLine" : 0
      },
      "40" : {
        "Text" : "# š rules\n",
        "Line" : 411,
        "CharPositionInLine" : 0
      },
      "41" : {
        "Text" : "# removing extra markers\n",
        "Line" : 416,
        "CharPositionInLine" : 0
      },
      "42" : {
        "Text" : "# tokeniser components\n",
        "Line" : 422,
        "CharPositionInLine" : 0
      },
      "43" : {
        "Text" : "# database to ftb3\n",
        "Line" : 442,
        "CharPositionInLine" : 0
      },
      "44" : {
        "Text" : "# database to apertium\n",
        "Line" : 462,
        "CharPositionInLine" : 0
      },
      "45" : {
        "Text" : "# database to monodix\n",
        "Line" : 476,
        "CharPositionInLine" : 0
      },
      "46" : {
        "Text" : "# database to giella\n",
        "Line" : 481,
        "CharPositionInLine" : 0
      },
      "47" : {
        "Text" : "# database (back) to kotus\n",
        "Line" : 492,
        "CharPositionInLine" : 0
      },
      "48" : {
        "Text" : "# }}}\n",
        "Line" : 496,
        "CharPositionInLine" : 1
      },
      "49" : {
        "Text" : "#\n\n# {{{ COMPILATION RECIPES\n\n# compile lexc\n",
        "Line" : 497,
        "CharPositionInLine" : 0
      },
      "50" : {
        "Text" : "# compile twolc\n",
        "Line" : 503,
        "CharPositionInLine" : 0
      },
      "51" : {
        "Text" : "# }}}\n\n#\n\n# {{{ GENERIC tagsetless stuff\n",
        "Line" : 517,
        "CharPositionInLine" : 0
      },
      "52" : {
        "Text" : "# Lemmatiser\n",
        "Line" : 522,
        "CharPositionInLine" : 0
      },
      "53" : {
        "Text" : "# segment\n",
        "Line" : 531,
        "CharPositionInLine" : 0
      },
      "54" : {
        "Text" : "# create one tape spell checker\n",
        "Line" : 540,
        "CharPositionInLine" : 0
      },
      "55" : {
        "Text" : "# create basic corpus tokeniser\n\n# Should split at even-odd boundaries of word punct* word punct*\n",
        "Line" : 551,
        "CharPositionInLine" : 0
      },
      "56" : {
        "Text" : "# hyphenation dictionary\n",
        "Line" : 567,
        "CharPositionInLine" : 0
      },
      "57" : {
        "Text" : "# }}}\n\n#\n\n# {{{ GENERIC label segments\n\n# word-boundary huphens\n",
        "Line" : 585,
        "CharPositionInLine" : 0
      },
      "58" : {
        "Text" : "# spelling variations\n",
        "Line" : 598,
        "CharPositionInLine" : 0
      },
      "59" : {
        "Text" : "# case variations\n",
        "Line" : 608,
        "CharPositionInLine" : 0
      },
      "60" : {
        "Text" : "# remove remaining morph boundaries at this point\n",
        "Line" : 614,
        "CharPositionInLine" : 0
      },
      "61" : {
        "Text" : "#\n",
        "Line" : 621,
        "CharPositionInLine" : 0
      },
      "62" : {
        "Text" : "# }}}\n\n#\n\n# {{{FTB3 compilation\n",
        "Line" : 625,
        "CharPositionInLine" : 0
      },
      "63" : {
        "Text" : "# word-boundary huphens\n",
        "Line" : 629,
        "CharPositionInLine" : 0
      },
      "64" : {
        "Text" : "# spelling variations\n",
        "Line" : 635,
        "CharPositionInLine" : 0
      },
      "65" : {
        "Text" : "# case variations\n",
        "Line" : 645,
        "CharPositionInLine" : 0
      },
      "66" : {
        "Text" : "# make tag adjustments\n",
        "Line" : 651,
        "CharPositionInLine" : 0
      },
      "67" : {
        "Text" : "# remove remaining morph boundaries at this point\n",
        "Line" : 660,
        "CharPositionInLine" : 0
      },
      "68" : {
        "Text" : "# hand-written weights for ftb3\n",
        "Line" : 666,
        "CharPositionInLine" : 0
      },
      "69" : {
        "Text" : "# create morphological analyzer\n",
        "Line" : 671,
        "CharPositionInLine" : 0
      },
      "70" : {
        "Text" : "# finalising\n",
        "Line" : 676,
        "CharPositionInLine" : 0
      },
      "71" : {
        "Text" : "# create generator from analyzer\n",
        "Line" : 680,
        "CharPositionInLine" : 0
      },
      "72" : {
        "Text" : "# }}}\n\n#\n\n# {{{ FTB1 compilation\n\n# The FTB1 Makefile fragment was written by Miikka Silfverberg, with\n\n# file naming changed to match omorfi structure a bit by Flammie.\n\n#\n\n# This Makefile builds morphology.ftb1.ol which is the lookup\n\n# optimized FinnTreeBank 1 version of Omorfi.\n\n#\n\n# The ftb1-version of Omorfi is built from omorfi-omor.analyse.hfst\n\n# which can be found in the directory omorfi/src/generated.  You\n\n# should copy omorfi-omor.analyse.hfst into this directory.\n\n#\n\n# This Makefile was tested using Omorfi revision\n\n# 20141014-213-g12c4345.\n\n#\n\n# Differences between regular Omorfi and the ftb1 version:\n\n#\n\n# - Ftb1 uses a different label set than Omorfi.\n\n#\n\n# - Compound analyses where some of the parts are proper nouns are\n\n#   filtered out.\n\n#\n\n# - Minen-derivatives are analyzed as nouns with a noun lemma and\n\n#   Lex_Minen tag.\n\n#\n\n# - Sti-derivatives are analyzed as adverbs with an adverb lemma and\n\n#   Lex_Sti tags.\n\n#\n\n# - Only the last part of a compound gets analyzed. The earlier parts\n\n#   remain unanalyzed but a compound border marker '#' is inserted\n\n#   between compound parts.\n\n#\n\n# Author: Miikka Silfverberg 2015\n",
        "Line" : 686,
        "CharPositionInLine" : 0
      },
      "73" : {
        "Text" : "# Convert omorfi to tropical format via sfst format in order\n\n# to get rid of weights and add optional upper casing for all\n\n# words.\n",
        "Line" : 721,
        "CharPositionInLine" : 0
      },
      "74" : {
        "Text" : "# Add proper noun analyses with [LEX=MINEN] tags for all\n\n# Minen-derivatives. We need to change the lemma of the\n\n# analysis as well as the tags. Therefore we first need to\n\n# extract stems and re-build the analyses using the stems and\n\n# inflectional suffixes.\n",
        "Line" : 730,
        "CharPositionInLine" : 0
      },
      "75" : {
        "Text" : "# Get all word forms of the lemma 'miettiminen'.\n",
        "Line" : 739,
        "CharPositionInLine" : 0
      },
      "76" : {
        "Text" : "# Get inflectional suffixes of all front vowel\n\n# Minen-derivatives.\n",
        "Line" : 744,
        "CharPositionInLine" : 0
      },
      "77" : {
        "Text" : "# Get all word forms of the lemma 'avaaminen'.\n",
        "Line" : 752,
        "CharPositionInLine" : 0
      },
      "78" : {
        "Text" : "# Get inflectional suffixes of all back vowel\n\n# Minen-derivatives.\n",
        "Line" : 757,
        "CharPositionInLine" : 0
      },
      "79" : {
        "Text" : "# Get inflectional suffixes of all Minen-derivatives.\n",
        "Line" : 765,
        "CharPositionInLine" : 0
      },
      "80" : {
        "Text" : "# Get all Va-derivatives of verbs.\n",
        "Line" : 770,
        "CharPositionInLine" : 0
      },
      "81" : {
        "Text" : "# Get the stems of all Va-derivatives of verbs (these stems\n\n# are also stems [minus -minen] for Minen-derivatives).\n",
        "Line" : 776,
        "CharPositionInLine" : 0
      },
      "82" : {
        "Text" : "# Form complete analyses for Minen-derivatives by concatenating\n\n# stems, suffixes and markers.\n",
        "Line" : 783,
        "CharPositionInLine" : 0
      },
      "83" : {
        "Text" : "# Add proper adverb analyses with [LEX=STI] tags for all\n\n# Sti-derivatives. We need to change the lemma of the\n\n# analysis as well as the tags. Therefore we first need to\n\n# extract stems and re-build the analyses using the stems and\n\n# inflectional suffixes.\n",
        "Line" : 792,
        "CharPositionInLine" : 0
      },
      "84" : {
        "Text" : "# Get all word forms of the lemma 'ikuisesti'.\n",
        "Line" : 801,
        "CharPositionInLine" : 0
      },
      "85" : {
        "Text" : "# Get all word forms of the lemma 'pimeästi'.\n",
        "Line" : 806,
        "CharPositionInLine" : 0
      },
      "86" : {
        "Text" : "# Get inflectional suffixes of all front vowel\n\n# Sti-derivatives.\n",
        "Line" : 811,
        "CharPositionInLine" : 0
      },
      "87" : {
        "Text" : "# Get inflectional suffixes of all back vowel\n\n# Sti-derivatives.\n",
        "Line" : 819,
        "CharPositionInLine" : 0
      },
      "88" : {
        "Text" : "# Get inflectional suffixes of all Sti-derivatives.\n",
        "Line" : 827,
        "CharPositionInLine" : 0
      },
      "89" : {
        "Text" : "# Get all sen (singular genitive) forms of adjective.\n",
        "Line" : 832,
        "CharPositionInLine" : 0
      },
      "90" : {
        "Text" : "# Get the stems of all singular genitive adjectives (these\n\n# stems are also stems [minus -sti] for Sti-derivatives).\n",
        "Line" : 838,
        "CharPositionInLine" : 0
      },
      "91" : {
        "Text" : "# Form complete analyses for Sti-derivatives by concatenating\n\n# stems, suffixes and markers.\n",
        "Line" : 845,
        "CharPositionInLine" : 0
      },
      "92" : {
        "Text" : "# 1. Remove compounds where some parts are proper nouns. They are\n\n# problematic for disambiguation and almost never occur.\n\n# 2. Replace dash compound markers so that the type of the dash\n\n# can be identified on the output-level. This is needed for\n\n# recovering the correct dashes later.\n\n# 3. Remove [INF=MINEN] analyses that don't occur in ftb1.\n\n# 4. Remove {hyph?} markers that omorfi contains on the input\n\n# side (they're a bug and shouldn't be there).\n",
        "Line" : 854,
        "CharPositionInLine" : 0
      },
      "93" : {
        "Text" : "# Get prefixes of compounds and subsitute all compound markers\n\n# so that they can be identified both on the input and output\n\n# level.\n",
        "Line" : 871,
        "CharPositionInLine" : 0
      },
      "94" : {
        "Text" : "# Get all word forms that arenät compounds.\n",
        "Line" : 882,
        "CharPositionInLine" : 0
      },
      "95" : {
        "Text" : "# Compile a transducer where only final parts of compounds are\n\n# analyzed because that's the way ftb1 does it. The initial\n\n# parts should be left as they are.\n",
        "Line" : 887,
        "CharPositionInLine" : 0
      },
      "96" : {
        "Text" : "# 1. Remove word id markers and replace all omorfi labels with\n\n# corresponding ftb1 labels.\n\n# 2. Remove the duplicate marking of number in pronouns.\n\n# 3. Change all Pcle analyses to Adverb analyses.\n\n# 4. Remove duplicate word class markers that result from\n\n# substituting derivation tags.\n",
        "Line" : 900,
        "CharPositionInLine" : 0
      },
      "97" : {
        "Text" : "# Invert the argument fst.\n",
        "Line" : 917,
        "CharPositionInLine" : 0
      },
      "98" : {
        "Text" : "# }}}\n\n#\n\n# {{{OMOR compilation\n\n# small version\n",
        "Line" : 1162,
        "CharPositionInLine" : 0
      },
      "99" : {
        "Text" : "# spelling variations\n",
        "Line" : 1171,
        "CharPositionInLine" : 0
      },
      "100" : {
        "Text" : "# remove remaining morph boundaries at this point\n",
        "Line" : 1181,
        "CharPositionInLine" : 0
      },
      "101" : {
        "Text" : "# create morphological analyzer\n",
        "Line" : 1187,
        "CharPositionInLine" : 0
      },
      "102" : {
        "Text" : "# finalising\n",
        "Line" : 1192,
        "CharPositionInLine" : 0
      },
      "103" : {
        "Text" : "# simple recasing (DEPRECATED)\n",
        "Line" : 1196,
        "CharPositionInLine" : 0
      },
      "104" : {
        "Text" : "# Full lexicon\n",
        "Line" : 1203,
        "CharPositionInLine" : 0
      },
      "105" : {
        "Text" : "# spelling variations\n",
        "Line" : 1209,
        "CharPositionInLine" : 0
      },
      "106" : {
        "Text" : "# remove remaining morph boundaries at this point\n",
        "Line" : 1219,
        "CharPositionInLine" : 0
      },
      "107" : {
        "Text" : "# create morphological analyzer\n",
        "Line" : 1225,
        "CharPositionInLine" : 0
      },
      "108" : {
        "Text" : "# finalising\n",
        "Line" : 1230,
        "CharPositionInLine" : 0
      },
      "109" : {
        "Text" : "# simple recasing (DEPRECATED)\n",
        "Line" : 1234,
        "CharPositionInLine" : 0
      },
      "110" : {
        "Text" : "# create generator from large analyzer\n",
        "Line" : 1241,
        "CharPositionInLine" : 0
      },
      "111" : {
        "Text" : "# guesser\n",
        "Line" : 1246,
        "CharPositionInLine" : 0
      },
      "112" : {
        "Text" : "# spelling variations\n",
        "Line" : 1252,
        "CharPositionInLine" : 0
      },
      "113" : {
        "Text" : "# remove remaining morph boundaries at this point\n",
        "Line" : 1262,
        "CharPositionInLine" : 0
      },
      "114" : {
        "Text" : "# create morphological analyzer\n",
        "Line" : 1268,
        "CharPositionInLine" : 0
      },
      "115" : {
        "Text" : "# finalising\n",
        "Line" : 1273,
        "CharPositionInLine" : 0
      },
      "116" : {
        "Text" : "# }}}\n\n#\n\n# {{{APE compilation\n",
        "Line" : 1277,
        "CharPositionInLine" : 0
      },
      "117" : {
        "Text" : "# }}}\n\n#\n\n# {{{Giella comp\n",
        "Line" : 1288,
        "CharPositionInLine" : 0
      },
      "118" : {
        "Text" : "# }}}\n\n# {{{SPELL-CHECKING\n\n# voikko speller LIBHFST beta targets'\n",
        "Line" : 1303,
        "CharPositionInLine" : 0
      },
      "119" : {
        "Text" : "# }}}\n\n#\n\n# {{{ VISL CG 3\n",
        "Line" : 1330,
        "CharPositionInLine" : 0
      },
      "120" : {
        "Text" : "# }}}\n",
        "Line" : 1337,
        "CharPositionInLine" : 0
      },
      "121" : {
        "Text" : "# {{{ C++ library\n",
        "Line" : 1339,
        "CharPositionInLine" : 0
      },
      "122" : {
        "Text" : "# }}}\n\n# {{{ java library\n",
        "Line" : 1353,
        "CharPositionInLine" : 0
      },
      "123" : {
        "Text" : "# }}}\n\n# {{{ cleaning\n",
        "Line" : 1362,
        "CharPositionInLine" : 0
      },
      "124" : {
        "Text" : "# }}}\n",
        "Line" : 1430,
        "CharPositionInLine" : 0
      },
      "125" : {
        "Text" : "# {{{ other convenience targets...\n",
        "Line" : 1432,
        "CharPositionInLine" : 0
      },
      "126" : {
        "Text" : "# }}}\n",
        "Line" : 1438,
        "CharPositionInLine" : 0
      },
      "127" : {
        "Text" : "#\n\n# vim: set foldmethod=marker:\n",
        "Line" : 1440,
        "CharPositionInLine" : 0
      },
      "CommentCount" : 128
    },
    "src/phonology/Makefile.am" : {
      "ObjectId" : "ab65ec8c8c347ec26a40517b1b2ff8adccbacf47",
      "LastModified" : "2012-03-29T16:27:32Z",
      "FileType" : "AUTOMAKE",
      "0" : {
        "Text" : "## Process this file with automake to produce Makefile.in\n",
        "Line" : 1,
        "CharPositionInLine" : 0
      },
      "CommentCount" : 1
    },
    "src/spell-checking/Makefile.am" : {
      "ObjectId" : "c9b7716071e9261418fb74c44dcf5b38e6cd1238",
      "LastModified" : "2015-01-10T16:18:48Z",
      "FileType" : "AUTOMAKE",
      "0" : {
        "Text" : "## Process this file with automake to produce Makefile.in\n",
        "Line" : 1,
        "CharPositionInLine" : 0
      },
      "CommentCount" : 1
    },
    "src/voikko/voikko-fi_FI.pro" : {
      "ObjectId" : "12f2b6618ed8b22c1423c490f480f1407e4cb8e7",
      "LastModified" : "2015-01-10T16:18:48Z",
      "FileType" : "QMAKE",
      "CommentCount" : 0
    },
    "test/Makefile.am" : {
      "ObjectId" : "39c175353b6f988832c8a3762a64737c5c1fab61",
      "LastModified" : "2018-10-23T15:49:20Z",
      "FileType" : "AUTOMAKE",
      "0" : {
        "Text" : "## Process this file with automake to produce Makefile.in\n",
        "Line" : 1,
        "CharPositionInLine" : 0
      },
      "1" : {
        "Text" : "# order in slowness order\n",
        "Line" : 3,
        "CharPositionInLine" : 0
      },
      "2" : {
        "Text" : "#yaml-tests.yaml: test-header.yaml $(top_builddir)/src/lexical/gtd-tests.yaml\n\n#\tcat test-header.yaml gtd-tests.yaml > $@\n",
        "Line" : 39,
        "CharPositionInLine" : 0
      },
      "CommentCount" : 3
    }
  },
  "FileTypes" : {
    "QMAKE" : 1,
    "AUTOMAKE" : 7
  },
  "ElapsedTime" : 2654
}